{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fa3c297-723f-4cd7-97e9-e55a5b2aa4ed",
   "metadata": {},
   "source": [
    "# Tutorial 1: Simple Gaussian Mutual Information\n",
    "\n",
    "In this tutorial, we will generate some random data from a Gaussian distribution to see how to compute the mutual information (MI) for a set of data. A ReadTheDocs version of this tutorial can be found at: https://netsci.readthedocs.io/en/latest/tutorial1_simple_gaussian_mi.html.\n",
    "\n",
    "Make sure to activate the NetSci conda environment::\n",
    "```bash\n",
    "conda activate netsci\n",
    "```\n",
    "\n",
    "## Two Independent Gaussians\n",
    "\n",
    "The following Python code will sample data from two independent\n",
    "Gaussian distributions, with mean zero and standard deviation of 1, \n",
    "creating a file named 'sample.dat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06bdbba3-76e7-43ae-9941-7622eab68402",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 100 rows\n",
    "N = 100\n",
    "\n",
    "# 2 columns\n",
    "M = 2\n",
    "\n",
    "gaussian_2D = np.zeros((M, N)).astype(np.float32)\n",
    "for i in range(M):\n",
    "    gaussian_2D[i,:] = np.random.normal(size=N)\n",
    "\n",
    "with open(\"sample.dat\", \"w\") as f:\n",
    "    f.write(\"column1\\tcolumn2\\n\")\n",
    "    for i in range(N):\n",
    "        f.write(str(gaussian_2D[0,i])+\"\\t\"+str(gaussian_2D[1,i])+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c43232-b7ec-43a2-9076-3c8301bd5101",
   "metadata": {},
   "source": [
    "Inside sample.dat, there are two columns of data, each containing 100 rows\n",
    "(not including the header)\n",
    "\n",
    "```\n",
    "column1     column2\n",
    "-0.7315501  -0.2413269\n",
    "-1.012331   0.03488477\n",
    "-0.5544968  -1.5803745\n",
    "-0.86383635 0.91249526\n",
    "2.1049206   -0.46482915\n",
    "0.84087217  1.1912068\n",
    "2.6172605   1.1999675\n",
    "-0.52112085 0.1250357\n",
    "-0.9300766  0.73021877\n",
    "1.1873163   2.590006\n",
    "-1.0747769  -0.05441373\n",
    "...\n",
    "```\n",
    "\n",
    "Now, let us use NetSci to compute the MI between these two distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6196c9d0-7644-422d-b1b9-7ae8de56e39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import netcalc\n",
    "import cuarray\n",
    "\n",
    "# k-nearest neighbors number\n",
    "k = 1\n",
    "\n",
    "# Dimensionality of data\n",
    "d = 1\n",
    "\n",
    "# Two dimensions of distributions\n",
    "xd = 2\n",
    "\n",
    "# Number of data points in 2D distribution\n",
    "N = 100\n",
    "\n",
    "# Define all pair correlations that will be computed\n",
    "num_nodes = 2\n",
    "num_node_pairs = num_nodes**2\n",
    "ab = cuarray.IntCuArray()\n",
    "ab.init(num_node_pairs, 2)\n",
    "for i in range(num_nodes):\n",
    "    for j in range(num_nodes):\n",
    "        node_pair_index = i*num_nodes + j\n",
    "        ab[node_pair_index][0] = i\n",
    "        ab[node_pair_index][1] = j\n",
    "\n",
    "# Load the data into a numpy array\n",
    "data_list = []\n",
    "with open(\"sample.dat\", \"r\") as f:\n",
    "    for i, line in enumerate(f.readlines()):\n",
    "        if i == 0:\n",
    "            # Skip the data header\n",
    "            continue\n",
    "\n",
    "        line = line.strip().split()\n",
    "        col1_datum = line[0]\n",
    "        col2_datum = line[1]\n",
    "        data_list.append([col1_datum, col2_datum])\n",
    "\n",
    "assert len(data_list) == N\n",
    "\n",
    "two_columns_of_data = np.array(data_list, dtype=np.float32).T\n",
    "\n",
    "# The input array\n",
    "X = cuarray.FloatCuArray()\n",
    "X.fromNumpy2D(two_columns_of_data)\n",
    "\n",
    "# The output array\n",
    "I = cuarray.FloatCuArray()\n",
    "\n",
    "netcalc.mutualInformation(X, I, ab, k, N, xd, d, netcalc.GPU_PLATFORM)\n",
    "\n",
    "mutual_information = I[0][1]\n",
    "\n",
    "print(\"predicted mutual information for sample.dat:\", mutual_information)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222b43bd-33d4-4672-adf6-45279cb9329b",
   "metadata": {},
   "source": [
    "Let us consider the inputs to this script later. First, let's examine the output\n",
    "\n",
    "```\n",
    "predicted mutual information for sample.dat: -0.015671253204345703\n",
    "```\n",
    "\n",
    "The exact MI for two independent Gaussian distributions can be found exactly:\n",
    "\n",
    "$I_{exact}(X,Y)=-\\frac{1}{2}\\log{(1-r^2)}$\n",
    "\n",
    "Where $I_{exact}(X,Y)$ is the MI of the two Gaussian distributions $X$ \n",
    "and $Y$, and $r$ is the covariance of the two distributions, which in\n",
    "this case, is zero. Therefore, for $r=0$, $I_{exact}(X,Y)=0$, which is\n",
    "fairly close to the value we obtained in this case.\n",
    "\n",
    "Let us consider the inputs to the script above:\n",
    "\n",
    "- k\n",
    "\n",
    "  This is the \"k\" of \"k-nearest-neighbors\" - that is - how many neighbors to each point\n",
    "  are taken in Kraskov's algorithm. Kraskov recommends a value of \"k\" between 2 and 4, \n",
    "  although situations where k=6 have also been used. In general, a lower value of \"k\"\n",
    "  reduces bias, but increases noise, and a higher value of \"k\" reduces noise, but \n",
    "  increases bias for non-independent distributions. If testing for independence, bias\n",
    "  is not such an issue, so k can be as large as N/2, where N is the number of data points.\n",
    "  \n",
    "- d\n",
    "\n",
    "  Dimensionality of the data. Since these are 1D Gaussians, the dimensionality is equal to\n",
    "  one. In contrast, for example, the positions of atoms in a protein would be three-dimensional\n",
    "  data.\n",
    "  \n",
    "- xd\n",
    "  \n",
    "  The number of distributions per MI calculation. At this time, only the MI of two\n",
    "  distributions can be calculated at a time in NetSci, so xd=2.\n",
    "  \n",
    "- N\n",
    "  \n",
    "  The number of data points sampled from each distribution.\n",
    "  \n",
    "- ab\n",
    "  \n",
    "  An array that represents which pairs of distributions to compute. This can be adjusted\n",
    "  to exclude the computation of certain pairs of distributions, if desired.\n",
    "  \n",
    "- X\n",
    "  \n",
    "  The input data, converted to a form that NetSci can use directly.\n",
    "  \n",
    "- I\n",
    "  \n",
    "  The output MI, with entries for each pair of distributions specified for an MI calculation.\n",
    "  \n",
    "- netcalc.GPU_PLATFORM\n",
    "  \n",
    "  Instruct NetSci to use the GPU device to perform the MI calculation. Alternatively, one may\n",
    "  use the GPU by passing netcalc.CPU_PLATFORM as this argument.\n",
    "\n",
    "  ## Two Dependent Gaussians\n",
    "\n",
    "  Let us modify our data to include a strong dependency between the Gaussian distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab84f28c-6069-4f54-a888-3db63cb9a0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 100 rows\n",
    "N = 100\n",
    "\n",
    "# 2 columns\n",
    "M = 2\n",
    "\n",
    "covariance_value = 0.9\n",
    "\n",
    "def make_covariance_matrix(covariance_value):\n",
    "    cov = np.array([[1.0, covariance_value], [covariance_value, 1.0]])\n",
    "    return cov\n",
    "\n",
    "gaussian_2D_mean = np.zeros(2)\n",
    "gaussian_2D_cov = make_covariance_matrix(covariance_value)\n",
    "gaussian_2D = np.random.multivariate_normal(\n",
    "    mean=gaussian_2D_mean,\n",
    "    cov=gaussian_2D_cov,\n",
    "    size=N,\n",
    ").T.astype(np.float32)\n",
    "\n",
    "with open(\"sample.dat\", \"w\") as f:\n",
    "    f.write(\"column1\\tcolumn2\\n\")\n",
    "    for i in range(N):\n",
    "        f.write(str(gaussian_2D[0,i])+\"\\t\"+str(gaussian_2D[1,i])+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4fe3081-9334-49df-aadf-27dea99b423d",
   "metadata": {},
   "source": [
    "This time, when one runs the MI calculation, the predicted MI is much larger\n",
    "\n",
    "```\n",
    "predicted mutual information for sample.dat: 1.1769\n",
    "```\n",
    "\n",
    "This is due to the large covariance value between the two Gaussian distributions.\n",
    "\n",
    "## In Closing\n",
    "\n",
    "This tutorial demonstrates the MI calculation on a set of data that was generated artificially by sampling from a Gaussian distribution. One could repeat the same MI analysis on data that was generated from any other source and benefit from the large speedup enabled by GPU acceleration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859b5031-9542-4376-969a-e78de52bde19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
